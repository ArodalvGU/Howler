---
title: "Final Project"
author: "Alberto Rodriguez"
date: "1/12/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Mexico went through a significant change in internal governance structure with the constitutional reform on the liberalization of gas prices in 2016.  Between February and November of 2017 this liberalization process was implemented across the country, making the price of gasoline to go from a single price nationwide that was determined by the government, to a fully variable pricing system based on both the national and international markets.

For a nation that has deep ties to the national value of oil, this process was met with severe criticism hardly impacting the acting administration of Enrique Peña Nieto (2012-2018) and making it one of the main topics in the presidential campaign of 2018. In this election the liberalization of oil prices was touted as an extremely hurtful measure that would impact households across the country and ended up being on the slogans of the now President Andres Manuel López Obrador.

This brief report aims to create a model, using several Machine Learning Approaches that might predict how much do households spend in energy related expenditures as a way to provide better information on the effects of energy policies, focusing on the effect of gas prices thata arose from the enregy reform. Such a model would try to provide policy makers a more specific measurements of the impact of their policies. 

This model will be created using the National Survey of Household Income and Expenses by the National Institute of Statistics and Geography of Mexico which includes information on more than 74,000 observations of households in the country. This survey includes several variables at the household level, such as socioeconomic level, geographic data and expenditures directly associated with the price of gas such as public and private transportation.


## Background

On March 18, 1938, the President of Mexico, Lázaro Cárdenas, issued the Petroleum Expropriation, which consisted of the legal appropriation of the oil operations of 17 foreign companies that controlled the industry. The main reason for the Expropriation was the constant refusal of the international oil companies to improve the wage and labor conditions of the employees of this industry. With this mandate, it was established that the Mexican State would have total control over the production and commercialization of oil in national territory. On June 7, 1938 - the Petróleos Mexicanos (Pemex) parastatal was founded, endowed with the necessary powers to carry out all oil exploration, exploitation, refining and commercialization work in our country (Garcia, 2009).

Since then, oil and fuel have been deeply intertwined with development policies in Mexico. In the 1970’s oil production was touted by the government as the solution for the country’s development given the price surge of the commodity worldwide, and after the second largest oil field in the world called Cantarell was discovered by PEMEX, the political link to oil prices became stronger with almost a third of the government’s budget relying on oil revenues (Wood, 2018). 

But by 2008, Cantarell’s production had dropped and both petroleum and electricity national companies (PEMEX and CFE) became inefficient enterprises with high debt and dated technology. Despite investing more in oil and natural gas exploration and extraction, oil production went from 3.4 million barrels per day in 2004, to 2.5 million barrels per day in 2013 (Gobierno de la República México, 2013). On top of this, according to estimation, the subsidies to fuel prices would amount for more than 650 billion pesos from 2013 to 2016 potentially crippling the government budget. (Gutierrez Rodriguez, 2017)

To try to solve this problem, in 2013, the Congress passed a series of constitutional amendments promoted by former president Enrique Peña Nieto under the “Pact for Mexico” to open the industry to private and foreign investment for the first time in 75 years and aimed to overcome the legal obstacles that limited his progress, reconfiguring the iron-clad constitutional scheme that regulated the use of hydrocarbons since the 1940’s (Garcia Rivera, 2015). This included the liberalization of fuel prices that had been heavily subsidized and caused an increase of competition from international and Mexican private enterprises where more than 40 companies entered the fuel market. (Wood, 2018). 

However, the open nature of the liberalization process provided an opening for a rise in gas prices in early 2017 called by the press as the gasolinazo. This major crisis happened because of poor planning, supply bottlenecks, and infrastructure challenges when the government began to remove subsidies from fuel prices and adjust the prices to the market which were at the time recorded as the lowest, making the negative effects of liberalization harsher. In particular, it provided a platform for the opposition and branded it as one of the worst problems created by the administration with a focus on how it hurt the population. (Nikolewski, 2017). On the presidential campaign of 2018 the now President Lopez Obrador ran on anti-corruption platform and publicly stated that the reform had been a mistake that deeply hurt the people of Mexico. This approach will shed some light on the question of how variables such as the price gas can predict energy expenditures as a way to test that information.

## Literary Review 

Even though the Mexican case is an interesting example to understand how fuel pricing subsidies and regulations affect societies, there are already several studies that have tried to model the effects of fuel prices on other different sectors. These studies range from analyzing the specific changes on the automotive industry, to helping understand the commodity nature of oil and fuel and its position as a good that considered as inelastic. 



```{r Package Requirements}
require (readr)
require(readxl)
require(tidyverse)
require(dplyr)
require(lubridate)
require(haven)
require(reprex)
require(caret)
require(recipes)
```

## Getting Databases

```{r}
#Note that I'm taking away the spaces needed according to the specific values.

enigh2018 <- read_csv("Data/conjunto_de_datos_concentradohogar_enigh_2018_ns.csv")
#Household level survey for data on 2018 (after the price liberalization)

Inflation <- read_delim("Data/Inflation.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE, 
    skip = 11)
#Inflation month values for 2016-2019

PRECIO2018 <- read_delim("Data/PreciosPromedioMensuales.csv",";", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE, skip = 2)
#Monthly Gas prices for every state. 

Ingreso_2018 <- read_csv("Data/Ingreso_2018.csv")
#Income Datasubset that has the month every household was surveyed on 2016

geo2018<- read_csv("Data/ubic_geo_2018.csv")
#State and City Data that uses the same codes as the data from 2018

```

## Wrangling and Merging


```{r}
#######################  ENIGH 2018  ############################
## Initial Merging (Pre-splitting)

#Adding Column for signaling 2018 (for merging)
enigh2018_clean<-mutate(enigh2018,"year_"=2018)

#Merging State Name
enigh2018_clean<-left_join(enigh2018_clean,geo2018,by=c('ubica_geo' = 'ubic_geo'))

#Selecting Variables for the model. (THIS MIGHT CHANGE ACCORDING TO FURTHER ANALYSIS)
enigh2018_clean<-select(enigh2018_clean,folioviv,foliohog,est_socio,ing_cor,transporte,combus,year_,entidad,desc_ent,alimentos,vivienda,educa_jefe,salud,educa_espa)

#Droping secondary data for households (just main HH)
enigh2018_clean<- filter(enigh2018_clean,foliohog==1)

#Separating first month from Ingreso
Ingreso_2018<-select(Ingreso_2018,folioviv,foliohog,mes_1) 
Ingreso_2018<- filter(Ingreso_2018,foliohog==1) #drops secondary data
Ingreso_2018 <- Ingreso_2018[order(Ingreso_2018$folioviv, Ingreso_2018$mes_1, decreasing=TRUE),] #sort higher month in the top
Ingreso_2018 <- Ingreso_2018[!duplicated(Ingreso_2018$folioviv),]#Keeps Month or NA
Ingreso_2018$mes_1 <- Ingreso_2018$mes_1+1 #Corrects for "last month data"

#Merging months
enigh2018_clean<-left_join(enigh2018_clean,Ingreso_2018,by="folioviv") #merging to get the month
enigh2018_clean<-select(enigh2018_clean,-foliohog.x,-foliohog.y) #Re-clean
enigh2018_clean[is.na(enigh2018_clean)] <- 8  # adding August as the month for NA's

#Fuel price to all months.
PRECIO2018<-select(PRECIO2018,X1,X2,X3,X4)
colnames(PRECIO2018) <- c("desc_ent", "Precio", "year_","mes_1")
enigh2018_clean<-left_join(enigh2018_clean,PRECIO2018,by=c('desc_ent'='desc_ent','year_'='year_','mes_1'='mes_1')) #merge prices.

#merging inflation
Inflation$Fecha <- as.Date(Inflation$Fecha,"%d/%m/%Y") #Reading Date with lubridate
Inflation<-mutate(Inflation,mes_1=month(Inflation$Fecha)) #Create variable of month
Inflation<-mutate(Inflation,year_=year(Inflation$Fecha)) #Create variable of month
Inflation<-select(Inflation,SP30577,mes_1,year_)#select just monthly variation
enigh2018_clean<-left_join(enigh2018_clean,Inflation,by=c('mes_1' = 'mes_1','year_' = 'year_')) #merge prices.

```
Splitting the data.
```{r}
set.seed(123)
index = createDataPartition(enigh2018_clean$transporte,p=.8,list=F) 
train_data = enigh2018_clean[index,] # Use 80% of the data as training data 
test_data = enigh2018_clean[-index,] # holdout 20% as test data 
dim(train_data)
dim(test_data)
```
```{r}
sum(is.na(train_data))
summary(train_data)
```
```{r}
train_data %>% 
  select_if(is.numeric) %>% 
  gather(var,val) %>% 
  ggplot(aes(val,group=var)) +
  geom_histogram(bins = 10) +
  facet_wrap(~var,scales="free",ncol=4)
```

```{r}
# First, turn the season variable into a categorical variable
gen_cats = . %>% 
  mutate(soceco_status = as.factor(est_socio)) %>% 
  mutate(head_education = as.factor(educa_jefe)) %>% 
  select(-year_,-entidad,-mes_1,-folioviv,-desc_ent,-est_socio,-educa_jefe)

# Generate our recipe to preprocess the data 
rcp <- 
  recipe(transporte~.,train_data %>% gen_cats) %>% 
  step_dummy(all_nominal(),-all_outcomes()) %>% 
  step_range(all_numeric()) %>%  # Normalize scale
  prep()


# Apply the recipe to the training and test data
train_data2 <- bake(rcp,train_data %>% gen_cats)
test_data2 <- bake(rcp,test_data%>% gen_cats) # Need to transform the seasons data here as well. 

sum(is.na(train_data2))
```



```{r}
set.seed(1004) # set a seed for replication purposes 

folds <- createFolds(train_data2$transporte, k = 6) # Partition the data into 10 equal folds

sapply(folds,length)
```

```{r}
control_conditions <- 
  trainControl(method='cv', # K-fold cross validation
               index = folds # The indices for our folds (so they are always the same)
  )
```

```{r}
mod_lm <-
  train(transporte ~ .,          # Equation (outcome and everything else)
        data=train_data2, # Training data 
        method = "lm",    # linear model
        metric = "RMSE",   # mean squared error
        trControl = control_conditions # Cross validation conditions
  )
mod_lm
```

```{r}
mod_knn <-
  train(transporte ~ .,           # Equation (outcome and everything else)
        data=train_data2,  # Training data 
        method = "knn",    # K-Nearest Neighbors Algorithm
        metric = "RMSE",   # mean squared error
        trControl = control_conditions # Cross validation conditions
  )
mod_knn
```

```{r}
mod_rf <-
  train(transporte ~ ., # Equation (outcome and everything else)
        data=train_data2, # Training data 
        method = "ranger", # random forest (ranger is much faster than rf)
        metric = "RMSE",     # mean squared error
        trControl = control_conditions
  )
mod_rf
```
```{r}
plot(mod_rf)
```

```{r}
mod_list <-
  list(
    lm = mod_lm,
    knn = mod_knn,
    rf = mod_rf 
  )

# Resamples allows us to compare model output
resamples(mod_list)
```

```{r}
dotplot(resamples(mod_list),metric = "RMSE")
```

```{r}
dotplot(resamples(mod_list),metric = "Rsquared")
```

```{r}
pred <- predict(mod_lm,newdata = test_data2)
mse = sum(test_data2$transporte-pred^2)/nrow(test_data2)
mse 
```
